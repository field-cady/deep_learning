{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0981576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy, json, time, pickle\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "574f5293-330d-4dfc-a5b0-c0076a9204c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_key=open('openai_api_key.txt', 'r').read()\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Big dataset of chinese words to learn and chinese_chars,pinyin_pronunciation,english_meaning\n",
    "ALL_WORDS = [[p.strip() for p in l.split(',')] for l in open('chinese_words.txt').readlines()]\n",
    "ch2pinyin = dict((p[0], p[1]) for p in ALL_WORDS)\n",
    "ch2english = dict((p[0], p[2]) for p in ALL_WORDS)\n",
    "\n",
    "\n",
    "N_KNOWN = 30\n",
    "N_LEARNING = 5\n",
    "N_TARGET_SENTENCES = 5\n",
    "BATCH_SIZE = 20   # ask for several at once\n",
    "N_SUCCESS_TO_MEMORIZE = 2  # this many successes in a row --> word memorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f562570-5b68-436d-92fb-e26eb05ec877",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "The API call slowed down a LOT when I switched to the current prompt.\n",
    "It was much faster previously when I just asked for sentences\n",
    "and figured out the target words and pronunciation myself.\n",
    "'''\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Here are a list of \"Known words\" that you can use as much as you want,\n",
    "and a list of \"Target words\" - you can only use one of them in a sentence.\n",
    "That idea is that every sentence should have exactly one \"Target\" word\n",
    "and have all the other words be \"Known\" words.\n",
    "You may ONLY use words from the \"Known words\" list and the \"Target words\" list.\n",
    "Do NOT use any other words.\n",
    "You may repeat words.\n",
    "\n",
    "Known words:\n",
    "{known_words_s}\n",
    "\n",
    "Target words:\n",
    "{target_words_s}\n",
    "\n",
    "Task:\n",
    "Write {n} idiomatic, natural, everyday Chinese sentences.\n",
    "Each sentence must contain exactly one word from the \"Target words\" list\n",
    "and have the rest be from the \"Known words\" list.\n",
    "\n",
    "Each line should have the target word, the sentence (with spaces), pronunciation, and an English translation. \n",
    "Separated by pipes.\n",
    "\n",
    "Example lines:\n",
    "喜欢|我喜欢你|Wǒ xǐ huan nǐ|I like you\n",
    "朋友|你是我的朋友|Nǐ shì wǒ de péng you|You are my friend\n",
    "\"\"\"\n",
    "def get_lines(known_words: list[list[str]], target_words: list[list[str]], n, model=\"gpt-5-mini\") -> list[tuple[str,str]]:\n",
    "    known_words_s = ','.join(known_words)\n",
    "    target_words_s = ','.join(target_words)\n",
    "    prompt = PROMPT_TEMPLATE.format(**locals())\n",
    "    response = client.responses.create(\n",
    "        model = model,\n",
    "        input=prompt\n",
    "    )\n",
    "    lines = response.output_text.strip().splitlines()\n",
    "    lines = [l.split('|') for l in lines if l.count('|')==3 and l.split('|')[0] in target_words]\n",
    "    return lines\n",
    "#\n",
    "#get_lines(known_words, target_words, 5, model=\"gpt-5-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf93e86d-bd98-4bf9-82d5-4b2a3673a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovering saved state\n",
      "Initializing empty state\n"
     ]
    }
   ],
   "source": [
    "# Variable state\n",
    "\n",
    "try:\n",
    "    state = json.loads(open('state.json','r').read())\n",
    "    print('Recovering saved state')\n",
    "    assert False\n",
    "except:\n",
    "    print('Initializing empty state')\n",
    "    state = {\n",
    "        'known_words': [wb[0] for wb in ALL_WORDS[:N_KNOWN]],\n",
    "        'target_words': [wb[0] for wb in ALL_WORDS[N_KNOWN+1:N_KNOWN+N_LEARNING]],\n",
    "        'perf': {w[0]:[] for w in ALL_WORDS}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda7dfb-4b60-4a40-a578-a143faec4ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "target_words ['没', '吧', '把', '跟']\n",
      "known_words ['的', '在', '有', '一', '个', '我', '不', '是', '这', '他', '了', '你', '们', '也', '说', '就', '人', '都', '和', '来', '上', '去', '看', '为', '到', '能', '这儿', '那', '好', '想']\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print('\\n\\n** NEW ROUND **')\n",
    "    known_words, target_words, perf = state['known_words'], state['target_words'], state['perf']\n",
    "    print('target_words', target_words)\n",
    "    print('known_words', known_words)\n",
    "    assert not set(known_words).intersection(target_words)\n",
    "    sentences = get_lines(known_words, target_words, N_TARGET_SENTENCES)\n",
    "    for s in sentences: print(s)\n",
    "    for i, (tw, s, pron, trans) in enumerate(sentences):\n",
    "        print(f\"{i}. {s.replace(' ', '')}\")\n",
    "    time.sleep(1)\n",
    "    errors = input(\"Which numbers did you miss?\")\n",
    "    # print('errors', errors)\n",
    "    if errors=='end':\n",
    "        # End session\n",
    "        open('state.json','w').write(json.dumps(state))\n",
    "        break\n",
    "    errors = [int(x) for x in errors]\n",
    "    print('errors:', errors)\n",
    "    for i, (tw, s, pron, trans) in enumerate(sentences):\n",
    "        if i in errors:\n",
    "            print('Failed', tw)\n",
    "            print(s,'\\n',pron,'\\n',trans)\n",
    "            perf[tw].append('fail')\n",
    "        else:\n",
    "            # print('Suceeded', tw)\n",
    "            perf[tw].append('success')\n",
    "        if len(perf[tw])>N_SUCCESS_TO_MEMORIZE and set(perf[tw][-1*N_SUCCESS_TO_MEMORIZE:])==set(['success']):\n",
    "            assert not set(known_words).intersection(target_words)\n",
    "            if tw in target_words:\n",
    "                print('tw', tw)\n",
    "                print('target_words', target_words)\n",
    "                known_words.append(tw)\n",
    "                state['target_words'] = [w for w in target_words if w != tw]\n",
    "                new_wb = [wb for wb in ALL_WORDS if wb[0] not in known_words][0]\n",
    "                state['target_words'].append(new_wb[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
