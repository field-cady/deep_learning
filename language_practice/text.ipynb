{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0981576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy, json, time\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1674ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['的', 'de', 'grammatical particle indicating possession or description'], ['在', 'zài', 'at; in; located at'], ['有', 'yǒu', 'to have; there is'], ['一', 'yī', 'one'], ['个', 'gè', 'general measure word'], ['我', 'wǒ', 'I; me'], ['不', 'bù', 'not'], ['是', 'shì', 'to be'], ['这', 'zhè', 'this'], ['他', 'tā', 'he; him'], ['了', 'le', 'completed action or change‑of‑state particle'], ['你', 'nǐ', 'you'], ['们', 'men', 'plural marker for people'], ['也', 'yě', 'also'], ['说', 'shuō', 'to say; to speak'], ['就', 'jiù', 'then; only'], ['人', 'rén', 'person; people'], ['都', 'dōu', 'all; both'], ['和', 'hé', 'and; with'], ['来', 'lái', 'to come'], ['上', 'shàng', 'on; above'], ['去', 'qù', 'to go'], ['看', 'kàn', 'to look; to see'], ['为', 'wèi', 'for'], ['到', 'dào', 'to arrive; to reach'], ['能', 'néng', 'can; to be able to'], ['这儿', 'zhèr', 'here'], ['那', 'nà', 'that'], ['好', 'hǎo', 'good'], ['想', 'xiǎng', 'to want; to think']]\n",
      "[['没', 'méi', 'not have; didn’t'], ['吧', 'ba', 'sentence‑final question particle'], ['把', 'bǎ', 'object‑marking particle'], ['跟', 'gēn', 'with; and']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = OpenAI(api_key=open('openai_api_key.txt', 'r').read())\n",
    "\n",
    "ALL_WORDS = [[p.strip() for p in l.split(',')] for l in open('chinese_words.txt').readlines()]\n",
    "\n",
    "N_KNOWN = 30\n",
    "N_LEARNING = 5\n",
    "KNOWN_WORDS = ALL_WORDS[:N_KNOWN]\n",
    "TARGET_WORDS = ALL_WORDS[N_KNOWN+1:N_KNOWN+N_LEARNING]\n",
    "print(KNOWN_WORDS)\n",
    "print(TARGET_WORDS)\n",
    "\n",
    "KNOWN_WORDS_CH = [p[0] for p in KNOWN_WORDS]\n",
    "TARGET_WORDS_CH = [p[0] for p in TARGET_WORDS]\n",
    "\n",
    "N_TARGET_SENTENCES = 5\n",
    "BATCH_SIZE = 20   # ask for several at once\n",
    "\n",
    "def is_valid(sentence, allowed):\n",
    "    words = sentence.lower().split('')\n",
    "    return all(word in allowed for word in words)\n",
    "\n",
    "def get_sentences(known_words: list[str], target_words: list[str], n, model=\"gpt-5-mini\") -> list[str]:\n",
    "    prompt = f\"\"\"\n",
    "Here are a list of \"Known words\" that you can use as much as you want,\n",
    "and a list of \"Target words\" - you can only use one of them in a sentence.\n",
    "That idea is that every sentence should have exactly one \"Target\" word\n",
    "and have all the other words be \"Known\" words.\n",
    "You may ONLY use words from the \"Known words\" list and the \"Target words\" list.\n",
    "Do NOT use any other words.\n",
    "You may repeat words.\n",
    "\n",
    "Known words:\n",
    "{\",\".join(known_words)}\n",
    "\n",
    "Target words:\n",
    "{\",\".join(target_words)}\n",
    "\n",
    "Task:\n",
    "Write {n} idiomatic, natural, everyday Chinese sentences.\n",
    "Each sentence must contain exactly one word from the \"Target words\" list\n",
    "and have the rest be from the \"Known words\" list.\n",
    "Put spaces between the words.\n",
    "One sentence per line.\n",
    "\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model = model,\n",
    "        input=prompt\n",
    "    )\n",
    "    lines = response.output_text.strip().splitlines()\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        words_in_line = line.split()\n",
    "        n_target = len([w for w in words_in_line if w in target_words])\n",
    "        n_known = len([w for w in words_in_line if w in known_words])\n",
    "        #print(n_target, '   ', line)\n",
    "        if n_target == 1 and n_known == len(words_in_line)-1:\n",
    "            sentences.append(line)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "#while len(sentences) < TARGET_SENTENCES:\n",
    "if False:\n",
    "    sentences = get_sentences(KNOWN_WORDS_CH, TARGET_WORDS_CH, N_TARGET_SENTENCES)\n",
    "    print('Sentences', sentences)\n",
    "    # Done\n",
    "    print('\\n')\n",
    "    for i, s in enumerate(sentences):\n",
    "        print(f\"{i}. {s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67fca19d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 他没来\n",
      "1. 你们去吧\n",
      "2. 你把那个看\n",
      "3. 我跟他来\n",
      "4. 这儿好吧\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which numbers did you miss? 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 把\n",
      "你 把 那 个 看\n",
      "nǐ bǎ nà gè kàn\n",
      "   你  nǐ  you\n",
      "   把  bǎ  object‑marking particle\n",
      "   那  nà  that\n",
      "   个  gè  general measure word\n",
      "   看  kàn  to look; to see\n",
      "Failed 跟\n",
      "我 跟 他 来\n",
      "wǒ gēn tā lái\n",
      "   我  wǒ  I; me\n",
      "   跟  gēn  with; and\n",
      "   他  tā  he; him\n",
      "   来  lái  to come\n",
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 我没想好\n",
      "1. 我们去看吧\n",
      "2. 他把这个说了\n",
      "3. 我跟你去\n",
      "4. 你没来也好\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which numbers did you miss? 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 跟\n",
      "我 跟 你 去\n",
      "wǒ gēn nǐ qù\n",
      "   我  wǒ  I; me\n",
      "   跟  gēn  with; and\n",
      "   你  nǐ  you\n",
      "   去  qù  to go\n",
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 我没说\n",
      "1. 我跟你来\n",
      "2. 你把这看看\n",
      "3. 他没来\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which numbers did you miss? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 我没有看到你\n",
      "1. 你来吧\n",
      "2. 我把这个看了\n",
      "3. 我跟你去\n",
      "4. 他没在这儿\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which numbers did you miss? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned word 没\n",
      "New word: ['个儿', 'gèr', 'measure word variant']\n",
      "Learned word 没\n",
      "[['吧', 'ba', 'sentence‑final question particle'], ['把', 'bǎ', 'object‑marking particle'], ['跟', 'gēn', 'with; and'], ['个儿', 'gèr', 'measure word variant']]\n",
      "['没', '吧', '把', '跟']\n",
      "Perf {'的': [], '在': [], '有': [], '一': [], '个': [], '我': [], '不': [], '是': [], '这': [], '他': [], '了': [], '你': [], '们': [], '也': [], '说': [], '就': [], '人': [], '都': [], '和': [], '来': [], '上': [], '去': [], '看': [], '为': [], '到': [], '能': [], '这儿': [], '那': [], '好': [], '想': [], '个儿': [], '没': ['success', 'success', 'success', 'success', 'success', 'success', 'success'], '吧': ['success', 'success', 'success', 'success'], '把': ['fail', 'success', 'success', 'success'], '跟': ['fail', 'fail', 'success', 'success'], '又': [], '把握': [], '啥': [], '还': [], '对': [], '过': [], '能干': [], '所以': [], '因为': [], '什么': [], '怎么': [], '太': [], '请': [], '觉得': [], '知道': [], '可以': [], '应该': [], '现在': [], '刚': [], '别': [], '真的': [], '时候': [], '自己': [], '因为的': [], '什么的': [], '然后': [], '还有': [], '比如': [], '第一': [], '第二': [], '不但': [], '而且': [], '其实': [], '虽然': [], '虽然的': [], '特别': [], '比如说': [], '可能': [], '非常': [], '比如的': [], '这个': [], '那个': [], '这些': [], '那些': [], '大家': [], '朋友': [], '工作': [], '工作人': [], '学习': [], '学校': [], '老师': [], '学生': [], '公司': [], '事情': [], '问题': [], '回答': [], '吃': [], '喝': [], '饭': [], '水': [], '茶': [], '咖啡': [], '牛奶': [], '面包': [], '水果': [], '苹果': [], '香蕉': [], '橙子': [], '菜': [], '肉': [], '鱼': [], '鸡': [], '蛋': [], '面': [], '米饭': [], '糖': [], '盐': [], '油': [], '饭店': [], '餐厅': [], '厨房': [], '桌子': [], '椅子': [], '杯子': [], '碗': [], '刀': [], '叉': [], '勺子': [], '吃饭': [], '喝水': [], '早餐': [], '午餐': [], '晚餐': [], '零食': [], '饼干': [], '巧克力': [], '面条': [], '汤': [], '冰': [], '热': [], '冷': [], '舒服': [], '难受': [], '累': [], '高兴': [], '快乐': [], '伤心': [], '生气': [], '紧张': [], '害怕': [], '担心': [], '放松': [], '惊讶': [], '累了': [], '饿': [], '渴': [], '病了': [], '疼痛': [], '快乐的': [], '高兴的': [], '难过': [], '疲倦': [], '轻松': [], '惊讶的': [], '爱': [], '喜欢': [], '讨厌': [], '家人': [], '父母': [], '爸爸': [], '妈妈': [], '孩子': [], '儿子': [], '女儿': [], '兄弟': [], '姐妹': [], '爷爷': [], '奶奶': [], '外公': [], '外婆': [], '丈夫': [], '妻子': [], '爱人': [], '亲戚': [], '邻居': [], '朋友们': [], '家': [], '家庭': [], '结婚': [], '离婚': [], '男朋友': [], '女朋友': [], '单身': [], '恋爱': [], '友谊': [], '亲密': [], '关系': [], '信任': [], '尊重': [], '沟通': [], '合作': [], '交流': [], '理解': [], '帮助': [], '支持': [], '照顾': [], '关心': [], '思念': [], '思考': [], '想念': [], '牵挂': [], '开心': [], '满足': [], '失望': [], '同学': [], '考试': [], '成绩': [], '作业': [], '知识': [], '能力': [], '技能': [], '经验': [], '发展': [], '进步': [], '学习的': [], '教育': [], '培训': [], '课程': [], '班级': [], '学期': [], '假期': [], '图书馆': [], '实验室': [], '研究': [], '调查': [], '科学': [], '技术': [], '工程': [], '创新': [], '方法': [], '策略': [], '计划': [], '安排': [], '目标': [], '任务': [], '项目': [], '进展': [], '完成': [], '效率': [], '成果': [], '机会': [], '选择': [], '决定': [], '态度': [], '性格': [], '行为': [], '习惯': [], '道德': [], '责任': [], '义务': [], '权利': [], '自由': [], '社会': [], '国家': [], '政府': [], '法律': [], '法规': [], '政策': [], '经济': [], '市场': [], '企业': [], '行业': [], '组织': [], '团队': [], '领导': [], '员工': [], '同事': [], '职位': [], '管理': [], '监督': [], '文化': [], '传统': [], '历史': [], '故事': [], '传说': [], '艺术': [], '音乐': [], '舞蹈': [], '绘画': [], '雕塑': [], '电影': [], '电视': [], '广播': [], '报纸': [], '杂志': [], '书': [], '小说': [], '文章': [], '诗': [], '语言': [], '文字': [], '汉字': [], '拼音': [], '句子': [], '词': [], '词语': [], '短语': [], '语法': [], '发音': [], '意思': [], '词典': [], '翻译': [], '解释': [], '信息': [], '消息': [], '数据': [], '分析': [], '结果': [], '影响': [], '作用': [], '效果': [], '方式': [], '文学': [], '诗歌': [], '爱情': [], '婚姻': [], '幸福': [], '感情': [], '鼓励': [], '安慰': [], '陪伴': []}\n",
      "target_words [['吧', 'ba', 'sentence‑final question particle'], ['把', 'bǎ', 'object‑marking particle'], ['跟', 'gēn', 'with; and'], ['个儿', 'gèr', 'measure word variant']]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerf\u001b[39m\u001b[38;5;124m'\u001b[39m, perf)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_words\u001b[39m\u001b[38;5;124m'\u001b[39m, target_words)\n\u001b[0;32m---> 60\u001b[0m tw_blob \u001b[38;5;241m=\u001b[39m \u001b[43mtw_hits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     61\u001b[0m known_words\u001b[38;5;241m.\u001b[39mappend(tw_blob)\n\u001b[1;32m     62\u001b[0m target_words\u001b[38;5;241m.\u001b[39mremove(tw_blob)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "ch2pinyin = dict((p[0], p[1]) for p in ALL_WORDS)\n",
    "ch2english = dict((p[0], p[2]) for p in ALL_WORDS)\n",
    "\n",
    "def get_error_report(s, known, target):\n",
    "    words = s.split()\n",
    "    ret = [s]\n",
    "    ret.append(' '.join([ch2pinyin[w] for w in words]))\n",
    "    for w in words:\n",
    "        ret.append(f'   {w}  {ch2pinyin[w]}  {ch2english[w]}')\n",
    "    return '\\n'.join(ret)\n",
    "\n",
    "\n",
    "known_words = copy.deepcopy(KNOWN_WORDS)\n",
    "target_words = copy.deepcopy(TARGET_WORDS)\n",
    "\n",
    "\n",
    "perf = {w[0]:[] for w in ALL_WORDS}\n",
    "\n",
    "while True:\n",
    "    print('\\n\\n** NEW ROUND **')\n",
    "    known_words_ch = [p[0] for p in known_words]\n",
    "    target_words_ch = [p[0] for p in target_words]\n",
    "    # print('target_words_ch', target_words_ch)\n",
    "    sentences = get_sentences(known_words_ch, target_words_ch, N_TARGET_SENTENCES)\n",
    "    # print('sentences', sentences)\n",
    "    for i, s in enumerate(sentences):\n",
    "        print(f\"{i}. {s.replace(' ', '')}\")\n",
    "    time.sleep(1)\n",
    "    errors = input(\"Which numbers did you miss?\")\n",
    "    # print('errors', errors)\n",
    "    if errors=='end': break\n",
    "    errors = [int(x) for x in errors]\n",
    "    for i, s in enumerate(sentences):\n",
    "        words = s.split()\n",
    "        # print('words', words)\n",
    "        hits = [w for w in words if w in target_words_ch]\n",
    "        if len(hits) ==0:\n",
    "                print(target_words)\n",
    "                print(target_words_ch)\n",
    "                print('Perf', perf)\n",
    "                print('target_words', target_words)\n",
    "        tw = hits[0]\n",
    "        if i in errors:\n",
    "            print('Failed', tw)\n",
    "            print(get_error_report(sentences[i], known_words, target_words))\n",
    "            perf[tw].append('fail')\n",
    "        else:\n",
    "            # print('Suceeded', tw)\n",
    "            perf[tw].append('success')\n",
    "        if len(perf[tw])>5 and set(perf[tw][-5:])==set(['success']):\n",
    "            print('Learned word', tw)\n",
    "            tw_hits = [wb for wb in target_words if wb[0]==tw]\n",
    "            if len(tw_hits) != 1:\n",
    "                print(target_words)\n",
    "                print(target_words_ch)\n",
    "                print('Perf', perf)\n",
    "                print('target_words', target_words)\n",
    "            tw_blob = tw_hits[0]\n",
    "            known_words.append(tw_blob)\n",
    "            target_words.remove(tw_blob)\n",
    "            new_wb = [wb for wb in ALL_WORDS if wb not in known_words and wb not in target_words][0]\n",
    "            print('New word:', new_wb)\n",
    "            target_words.append(new_wb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b4fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You typed: foobar\n"
     ]
    }
   ],
   "source": [
    "x = input(\"foo: \")\n",
    "print(\"You typed:\", x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64080420",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb3628",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 3\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m allowed_words \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslept\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     15\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mYou may ONLY use words from the following list.\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mDo NOT use any other words.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124mWrite 3 simple sentences.\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_client.py:137\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    135\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Example prompt\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "allowed_words = [\n",
    "    \"the\",\n",
    "    \"cat\",\n",
    "    \"sat\",\n",
    "    \"on\",\n",
    "    \"mat\",\n",
    "    \"and\",\n",
    "    \"slept\"\n",
    "]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You may ONLY use words from the following list.\n",
    "Do NOT use any other words.\n",
    "You may repeat words.\n",
    "Do NOT use punctuation that implies new words.\n",
    "\n",
    "Allowed words:\n",
    "{\", \".join(allowed_words)}\n",
    "\n",
    "Task:\n",
    "Write 3 simple sentences.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f407c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Draft\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=open('openai_api_key.txt', 'r').read())\n",
    "\n",
    "ALL_WORDS = [[p.strip() for p in l.split(',')] for l in open('chinese_words.txt').readlines()]\n",
    "KNOWN_WORDS = ALL_WORDS[:20]\n",
    "WORKING_ON = ALL_WORDS[21:25]\n",
    "\n",
    "\n",
    "TOP_100_CHARACTERS = (\"的一是不在人有我他这个们中来上大为和国地到以说时\"\n",
    "                      \"要就出会可也你对生能而子那得于着下自之年过发后作\"\n",
    "                      \"里用道行所然家种事成方多经么去法学如都同现当没动\"\n",
    "                      \"面起看定天分还进好小部其些主样理心她本前开但因只从想实\")\n",
    "\n",
    "WORKING_ON = (\"为国地到以时\"\n",
    "                      \"要就出会可也对生能而子那得于着自之年过发后作\"\n",
    "                      \"里道行所然家种事成方经么去法学如都同现当没动\"\n",
    "                      \"面起看定分还进好小部其些主样理心她本前开但因只从实\")\n",
    "\n",
    "COMMON_WORDS = [\n",
    "    \"的\", \"我\", \"你\", \"是\", \"了\", \"不\", \"在\", \"他\", \"我们\", \"这\",\n",
    "    \"有\", \"会\", \"个\", \"们\", \"来\", \"上\", \"大\", \"和\", \"要\", \"去\",\n",
    "    \"说\", \"也\", \"为\", \"她\", \"吗\", \"那\", \"可以\", \"知道\", \"你们\", \"现在\",\n",
    "    \"时间\", \"看\", \"好\", \"喜欢\", \"想\", \"对\", \"还是\", \"为什么\", \"怎么\", \"一点\",\n",
    "    \"怎么了\", \"一点儿\", \"因为\", \"所以\", \"应该\", \"知道吗\", \"觉得\", \"呢\", \"自己的\", \"觉得呢\",\n",
    "    \"觉得吗\", \"孩子\", \"老师\", \"朋友\", \"学校\", \"公司\", \"事情\", \"地方\", \"家\", \"家庭\",\n",
    "    \"工作\", \"生活\", \"孩子们\", \"东西\", \"问题\", \"可能\", \"人们\", \"社会\", \"别人\", \"世界\",\n",
    "    \"学习\", \"帮助\", \"已经\", \"一起\", \"开始\", \"结束\", \"继续\", \"第一次\", \"最后\", \"更多\",\n",
    "    \"少\", \"很多\", \"每个\", \"每个人\", \"所有\", \"只有\", \"真的\", \"可能吗\", \"需要\", \"得到\",\n",
    "    \"最好\", \"非常\", \"特别\", \"觉得很\", \"感到\", \"听说\", \"明白\", \"理解\", \"看见\", \"听见\",\n",
    "    \"告诉\", \"问\", \"回答\", \"担心\", \"希望\", \"感觉\", \"记得\", \"忘记\", \"带来\", \"关心\"\n",
    "]\n",
    "\n",
    "KNOWN_WORDS = [\n",
    "    \"的\", \"我\", \"你\", \"是\", \"了\", \"不\", \"在\", \"他\", \"我们\", \"这\",\n",
    "    \"有\", \"会\", \"个\", \"们\", \"来\", \"上\", \"大\", \"和\", \"要\", \"去\",\n",
    "    \"说\", \"也\", \"为\", \"她\", \"吗\", \"那\", \"可以\", \"知道\", \"你们\", \"现在\",\n",
    "    \"一点\", \"好\", \"朋友\", \"还是\",\n",
    "    # \"时间\", \"看\", \"喜欢\", \"想\", \"对\", \"为什么\", \"怎么\", \n",
    "    # \"怎么了\", \"一点儿\", \"因为\", \"所以\", \"应该\", \"知道吗\", \"觉得\", \"呢\", \"自己的\", \"觉得呢\",\n",
    "    # \"觉得吗\", \"孩子\", \"老师\", \"学校\", \"公司\", \"事情\", \"地方\", \"家\", \"家庭\",\n",
    "]\n",
    "\n",
    "TARGET_WORDS = [\n",
    "    \"们\", \"来\", \"上\", \"去\",\n",
    "    \"那\", \"可以\", \"知道\", \"你们\", \"现在\",\n",
    "    #\"时间\", \"看\", \"好\", \"喜欢\", \"想\", \"对\", \"还是\", \"为什么\", \"怎么\", \"一点\",\n",
    "    # \"怎么了\", \"一点儿\", \"因为\", \"所以\", \"应该\", \"知道吗\", \"觉得\", \"呢\", \"自己的\", \"觉得呢\",\n",
    "    # \"觉得吗\", \"孩子\", \"老师\", \"朋友\", \"学校\", \"公司\", \"事情\", \"地方\", \"家\", \"家庭\",\n",
    "    # \"工作\", \"生活\", \"孩子们\", \"东西\", \"问题\", \"可能\", \"人们\", \"社会\", \"别人\", \"世界\",\n",
    "    # \"学习\", \"帮助\", \"已经\", \"一起\", \"开始\", \"结束\", \"继续\", \"第一次\", \"最后\", \"更多\",\n",
    "    # \"少\", \"很多\", \"每个\", \"每个人\", \"所有\", \"只有\", \"真的\", \"可能吗\", \"需要\", \"得到\",\n",
    "    # \"最好\", \"非常\", \"特别\", \"觉得很\", \"感到\", \"听说\", \"明白\", \"理解\", \"看见\", \"听见\",\n",
    "    # \"告诉\", \"问\", \"回答\", \"担心\", \"希望\", \"感觉\", \"记得\", \"忘记\", \"带来\", \"关心\"\n",
    "]\n",
    "\n",
    "\n",
    "TARGET_SENTENCES = 5\n",
    "BATCH_SIZE = 20   # ask for several at once\n",
    "\n",
    "def is_valid(sentence, allowed):\n",
    "    words = sentence.lower().split('')\n",
    "    return all(word in allowed for word in words)\n",
    "\n",
    "def get_prompt(known_words, target_words, n):\n",
    "    prompt = f\"\"\"\n",
    "You may ONLY use words from the \"Known words\" list\n",
    "and the \"Target words\" list.\n",
    "Do NOT use any other words.\n",
    "You may repeat words.\n",
    "Make sure that each sentence has exactly ONE word from the\n",
    "\"Target words\" list, and the rest are from the \"Known words\" list.\n",
    "Do NOT use punctuation, but DO put a space between the words in a sentence.\n",
    "\n",
    "Known words:\n",
    "{\",\".join(known_words)}\n",
    "\n",
    "Target words:\n",
    "{\",\".join(target_words)}\n",
    "\n",
    "Task:\n",
    "Write {n} idiomatic, normal-sounding sentences.\n",
    "Each sentence must contain exactly one word from the \"Target words\" list\n",
    "and have the rest be from the \"Known words\" list.\n",
    "One sentence per line.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "sentences = []\n",
    "\n",
    "#while len(sentences) < TARGET_SENTENCES:\n",
    "if True:\n",
    "    #remaining = TARGET_SENTENCES - len(sentences)\n",
    "    prompt = get_prompt(KNOWN_WORDS, TARGET_WORDS,TARGET_SENTENCES )\n",
    "\n",
    "    response = client.responses.create(\n",
    "        # model=\"gpt-4.1-mini\",\n",
    "        model = \"gpt-4.1-nano\",\n",
    "        input=prompt\n",
    "    )\n",
    "\n",
    "    lines = response.output_text.strip().splitlines()\n",
    "    print(lines)\n",
    "\n",
    "    for line in lines:\n",
    "        words_in_line = line.split()\n",
    "        n_target = len([w for w in words_in_line if w in TARGET_WORDS])\n",
    "        print(n_target, '   ', line)\n",
    "        if n_target == 1:\n",
    "            sentences.append(line)\n",
    "\n",
    "# Done\n",
    "print('\\n')\n",
    "for i, s in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {s}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
