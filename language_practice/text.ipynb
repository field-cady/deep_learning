{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0981576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy, json, time\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1674ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['的', 'de', 'grammatical particle indicating possession or description'], ['在', 'zài', 'at; in; located at'], ['有', 'yǒu', 'to have; there is'], ['一', 'yī', 'one'], ['个', 'gè', 'general measure word'], ['我', 'wǒ', 'I; me'], ['不', 'bù', 'not'], ['是', 'shì', 'to be'], ['这', 'zhè', 'this'], ['他', 'tā', 'he; him'], ['了', 'le', 'completed action or change‑of‑state particle'], ['你', 'nǐ', 'you'], ['们', 'men', 'plural marker for people'], ['也', 'yě', 'also'], ['说', 'shuō', 'to say; to speak'], ['就', 'jiù', 'then; only'], ['人', 'rén', 'person; people'], ['都', 'dōu', 'all; both'], ['和', 'hé', 'and; with'], ['来', 'lái', 'to come'], ['上', 'shàng', 'on; above'], ['去', 'qù', 'to go'], ['看', 'kàn', 'to look; to see'], ['为', 'wèi', 'for'], ['到', 'dào', 'to arrive; to reach'], ['能', 'néng', 'can; to be able to'], ['这儿', 'zhèr', 'here'], ['那', 'nà', 'that'], ['好', 'hǎo', 'good'], ['想', 'xiǎng', 'to want; to think']]\n",
      "[['没', 'méi', 'not have; didn’t'], ['吧', 'ba', 'sentence‑final question particle'], ['把', 'bǎ', 'object‑marking particle'], ['跟', 'gēn', 'with; and']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = OpenAI(api_key=open('openai_api_key.txt', 'r').read())\n",
    "\n",
    "ALL_WORDS = [[p.strip() for p in l.split(',')] for l in open('chinese_words.txt').readlines()]\n",
    "\n",
    "N_KNOWN = 30\n",
    "N_LEARNING = 5\n",
    "KNOWN_WORDS = ALL_WORDS[:N_KNOWN]\n",
    "TARGET_WORDS = ALL_WORDS[N_KNOWN+1:N_KNOWN+N_LEARNING]\n",
    "print(KNOWN_WORDS)\n",
    "print(TARGET_WORDS)\n",
    "\n",
    "KNOWN_WORDS_CH = [p[0] for p in KNOWN_WORDS]\n",
    "TARGET_WORDS_CH = [p[0] for p in TARGET_WORDS]\n",
    "\n",
    "N_TARGET_SENTENCES = 5\n",
    "BATCH_SIZE = 20   # ask for several at once\n",
    "\n",
    "def is_valid(sentence, allowed):\n",
    "    words = sentence.lower().split('')\n",
    "    return all(word in allowed for word in words)\n",
    "\n",
    "def get_sentences(known_words: list[str], target_words: list[str], n, model=\"gpt-5-mini\") -> list[str]:\n",
    "    prompt = f\"\"\"\n",
    "Here are a list of \"Known words\" that you can use as much as you want,\n",
    "and a list of \"Target words\" - you can only use one of them in a sentence.\n",
    "That idea is that every sentence should have exactly one \"Target\" word\n",
    "and have all the other words be \"Known\" words.\n",
    "You may ONLY use words from the \"Known words\" list and the \"Target words\" list.\n",
    "Do NOT use any other words.\n",
    "You may repeat words.\n",
    "\n",
    "Known words:\n",
    "{\",\".join(known_words)}\n",
    "\n",
    "Target words:\n",
    "{\",\".join(target_words)}\n",
    "\n",
    "Task:\n",
    "Write {n} idiomatic, natural, everyday Chinese sentences.\n",
    "Each sentence must contain exactly one word from the \"Target words\" list\n",
    "and have the rest be from the \"Known words\" list.\n",
    "Put spaces between the words.\n",
    "One sentence per line.\n",
    "\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model = model,\n",
    "        input=prompt\n",
    "    )\n",
    "    lines = response.output_text.strip().splitlines()\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        words_in_line = line.split()\n",
    "        n_target = len([w for w in words_in_line if w in target_words])\n",
    "        n_known = len([w for w in words_in_line if w in known_words])\n",
    "        #print(n_target, '   ', line)\n",
    "        if n_target == 1 and n_known == len(words_in_line)-1:\n",
    "            sentences.append(line)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "#while len(sentences) < TARGET_SENTENCES:\n",
    "if False:\n",
    "    sentences = get_sentences(KNOWN_WORDS_CH, TARGET_WORDS_CH, N_TARGET_SENTENCES)\n",
    "    print('Sentences', sentences)\n",
    "    # Done\n",
    "    print('\\n')\n",
    "    for i, s in enumerate(sentences):\n",
    "        print(f\"{i}. {s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fca19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 我没看这个\n",
      "1. 我们去吧\n",
      "2. 你把那个看好\n",
      "3. 我跟你说\n",
      "4. 他没来\n",
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 我没来这儿\n",
      "1. 我们去看吧\n",
      "2. 你把这个看了\n",
      "3. 我跟他来\n",
      "4. 他没在这儿\n",
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 我没看到他\n",
      "1. 你们去吧\n",
      "2. 我把他看到了\n",
      "3. 我跟你说\n",
      "4. 这儿没人\n",
      "Learned word 没\n",
      "New word: ['个儿', 'gèr', 'measure word variant']\n",
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 我们去吧\n",
      "1. 你跟我来\n",
      "2. 你把他看好\n",
      "3. 这个儿好\n",
      "4. 我想你来看这儿吧\n",
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 你们来看我吧\n",
      "1. 我把这个看了\n",
      "2. 你跟我来\n",
      "3. 这儿有个儿好\n",
      "4. 你把这看上了\n",
      "Learned word 吧\n",
      "New word: ['又', 'yòu', 'again']\n",
      "Learned word 把\n",
      "New word: ['把握', 'bǎwò', 'to grasp; to hold']\n",
      "\n",
      "\n",
      "** NEW ROUND **\n",
      "0. 我跟你去看了\n",
      "1. 这个儿看上去不好\n",
      "2. 他又来了\n",
      "3. 我没把握吧\n",
      "4. 你跟我们来看吧\n",
      "Learned word 跟\n",
      "New word: ['啥', 'shá', 'what (colloquial)']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m words \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# print('words', words)\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m tw \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_words_ch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m errors:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed\u001b[39m\u001b[38;5;124m'\u001b[39m, tw)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "ch2pinyin = dict((p[0], p[1]) for p in ALL_WORDS)\n",
    "ch2english = dict((p[0], p[2]) for p in ALL_WORDS)\n",
    "\n",
    "def get_error_report(s, known, target):\n",
    "    words = s.split()\n",
    "    ret = [s]\n",
    "    ret.append(' '.join([ch2pinyin[w] for w in words]))\n",
    "    for w in words:\n",
    "        ret.append(f'   {w}  {ch2pinyin[w]}  {ch2english[w]}')\n",
    "    return '\\n'.join(ret)\n",
    "\n",
    "\n",
    "known_words = copy.deepcopy(KNOWN_WORDS)\n",
    "target_words = copy.deepcopy(TARGET_WORDS)\n",
    "\n",
    "\n",
    "perf = {w[0]:[] for w in ALL_WORDS}\n",
    "\n",
    "while True:\n",
    "    print('\\n\\n** NEW ROUND **')\n",
    "    known_words_ch = [p[0] for p in known_words]\n",
    "    target_words_ch = [p[0] for p in target_words]\n",
    "    # print('target_words_ch', target_words_ch)\n",
    "    sentences = get_sentences(known_words_ch, target_words_ch, N_TARGET_SENTENCES)\n",
    "    # print('sentences', sentences)\n",
    "    for i, s in enumerate(sentences):\n",
    "        print(f\"{i}. {s.replace(' ', '')}\")\n",
    "    time.sleep(1)\n",
    "    errors = input(\"Which numbers did you miss?\")\n",
    "    # print('errors', errors)\n",
    "    if errors=='end': break\n",
    "    errors = [int(x) for x in errors]\n",
    "    for i, s in enumerate(sentences):\n",
    "        words = s.split()\n",
    "        # print('words', words)\n",
    "        hits = [w for w in words if w in target_words_ch]\n",
    "        if len(hits) ==0:\n",
    "                print(target_words)\n",
    "                print(target_words_ch)\n",
    "                print('Perf', perf)\n",
    "                print('target_words', target_words)\n",
    "        tw = hits[0]\n",
    "        if i in errors:\n",
    "            print('Failed', tw)\n",
    "            print(get_error_report(sentences[i], known_words, target_words))\n",
    "            perf[tw].append('fail')\n",
    "        else:\n",
    "            # print('Suceeded', tw)\n",
    "            perf[tw].append('success')\n",
    "        if len(perf[tw])>5 and set(perf[tw][-5:])==set(['success']):\n",
    "            print('Learned word', tw)\n",
    "            tw_hits = [wb for wb in target_words if wb[0]==tw]\n",
    "            if len(tw_hits) != 1:\n",
    "                print(target_words)\n",
    "                print(target_words_ch)\n",
    "                print('Perf', perf)\n",
    "                print('target_words', target_words)\n",
    "            tw_blob = tw_hits[0]\n",
    "            known_words.append(tw_blob)\n",
    "            target_words.remove(tw_blob)\n",
    "            new_wb = [wb for wb in ALL_WORDS if wb not in known_words and wb not in target_words][0]\n",
    "            print('New word:', new_wb)\n",
    "            target_words.append(new_wb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b4fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You typed: foobar\n"
     ]
    }
   ],
   "source": [
    "x = input(\"foo: \")\n",
    "print(\"You typed:\", x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64080420",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb3628",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 3\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m allowed_words \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslept\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     15\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mYou may ONLY use words from the following list.\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mDo NOT use any other words.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124mWrite 3 simple sentences.\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_client.py:137\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    135\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Example prompt\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "allowed_words = [\n",
    "    \"the\",\n",
    "    \"cat\",\n",
    "    \"sat\",\n",
    "    \"on\",\n",
    "    \"mat\",\n",
    "    \"and\",\n",
    "    \"slept\"\n",
    "]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You may ONLY use words from the following list.\n",
    "Do NOT use any other words.\n",
    "You may repeat words.\n",
    "Do NOT use punctuation that implies new words.\n",
    "\n",
    "Allowed words:\n",
    "{\", \".join(allowed_words)}\n",
    "\n",
    "Task:\n",
    "Write 3 simple sentences.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f407c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Draft\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=open('openai_api_key.txt', 'r').read())\n",
    "\n",
    "ALL_WORDS = [[p.strip() for p in l.split(',')] for l in open('chinese_words.txt').readlines()]\n",
    "KNOWN_WORDS = ALL_WORDS[:20]\n",
    "WORKING_ON = ALL_WORDS[21:25]\n",
    "\n",
    "\n",
    "TOP_100_CHARACTERS = (\"的一是不在人有我他这个们中来上大为和国地到以说时\"\n",
    "                      \"要就出会可也你对生能而子那得于着下自之年过发后作\"\n",
    "                      \"里用道行所然家种事成方多经么去法学如都同现当没动\"\n",
    "                      \"面起看定天分还进好小部其些主样理心她本前开但因只从想实\")\n",
    "\n",
    "WORKING_ON = (\"为国地到以时\"\n",
    "                      \"要就出会可也对生能而子那得于着自之年过发后作\"\n",
    "                      \"里道行所然家种事成方经么去法学如都同现当没动\"\n",
    "                      \"面起看定分还进好小部其些主样理心她本前开但因只从实\")\n",
    "\n",
    "COMMON_WORDS = [\n",
    "    \"的\", \"我\", \"你\", \"是\", \"了\", \"不\", \"在\", \"他\", \"我们\", \"这\",\n",
    "    \"有\", \"会\", \"个\", \"们\", \"来\", \"上\", \"大\", \"和\", \"要\", \"去\",\n",
    "    \"说\", \"也\", \"为\", \"她\", \"吗\", \"那\", \"可以\", \"知道\", \"你们\", \"现在\",\n",
    "    \"时间\", \"看\", \"好\", \"喜欢\", \"想\", \"对\", \"还是\", \"为什么\", \"怎么\", \"一点\",\n",
    "    \"怎么了\", \"一点儿\", \"因为\", \"所以\", \"应该\", \"知道吗\", \"觉得\", \"呢\", \"自己的\", \"觉得呢\",\n",
    "    \"觉得吗\", \"孩子\", \"老师\", \"朋友\", \"学校\", \"公司\", \"事情\", \"地方\", \"家\", \"家庭\",\n",
    "    \"工作\", \"生活\", \"孩子们\", \"东西\", \"问题\", \"可能\", \"人们\", \"社会\", \"别人\", \"世界\",\n",
    "    \"学习\", \"帮助\", \"已经\", \"一起\", \"开始\", \"结束\", \"继续\", \"第一次\", \"最后\", \"更多\",\n",
    "    \"少\", \"很多\", \"每个\", \"每个人\", \"所有\", \"只有\", \"真的\", \"可能吗\", \"需要\", \"得到\",\n",
    "    \"最好\", \"非常\", \"特别\", \"觉得很\", \"感到\", \"听说\", \"明白\", \"理解\", \"看见\", \"听见\",\n",
    "    \"告诉\", \"问\", \"回答\", \"担心\", \"希望\", \"感觉\", \"记得\", \"忘记\", \"带来\", \"关心\"\n",
    "]\n",
    "\n",
    "KNOWN_WORDS = [\n",
    "    \"的\", \"我\", \"你\", \"是\", \"了\", \"不\", \"在\", \"他\", \"我们\", \"这\",\n",
    "    \"有\", \"会\", \"个\", \"们\", \"来\", \"上\", \"大\", \"和\", \"要\", \"去\",\n",
    "    \"说\", \"也\", \"为\", \"她\", \"吗\", \"那\", \"可以\", \"知道\", \"你们\", \"现在\",\n",
    "    \"一点\", \"好\", \"朋友\", \"还是\",\n",
    "    # \"时间\", \"看\", \"喜欢\", \"想\", \"对\", \"为什么\", \"怎么\", \n",
    "    # \"怎么了\", \"一点儿\", \"因为\", \"所以\", \"应该\", \"知道吗\", \"觉得\", \"呢\", \"自己的\", \"觉得呢\",\n",
    "    # \"觉得吗\", \"孩子\", \"老师\", \"学校\", \"公司\", \"事情\", \"地方\", \"家\", \"家庭\",\n",
    "]\n",
    "\n",
    "TARGET_WORDS = [\n",
    "    \"们\", \"来\", \"上\", \"去\",\n",
    "    \"那\", \"可以\", \"知道\", \"你们\", \"现在\",\n",
    "    #\"时间\", \"看\", \"好\", \"喜欢\", \"想\", \"对\", \"还是\", \"为什么\", \"怎么\", \"一点\",\n",
    "    # \"怎么了\", \"一点儿\", \"因为\", \"所以\", \"应该\", \"知道吗\", \"觉得\", \"呢\", \"自己的\", \"觉得呢\",\n",
    "    # \"觉得吗\", \"孩子\", \"老师\", \"朋友\", \"学校\", \"公司\", \"事情\", \"地方\", \"家\", \"家庭\",\n",
    "    # \"工作\", \"生活\", \"孩子们\", \"东西\", \"问题\", \"可能\", \"人们\", \"社会\", \"别人\", \"世界\",\n",
    "    # \"学习\", \"帮助\", \"已经\", \"一起\", \"开始\", \"结束\", \"继续\", \"第一次\", \"最后\", \"更多\",\n",
    "    # \"少\", \"很多\", \"每个\", \"每个人\", \"所有\", \"只有\", \"真的\", \"可能吗\", \"需要\", \"得到\",\n",
    "    # \"最好\", \"非常\", \"特别\", \"觉得很\", \"感到\", \"听说\", \"明白\", \"理解\", \"看见\", \"听见\",\n",
    "    # \"告诉\", \"问\", \"回答\", \"担心\", \"希望\", \"感觉\", \"记得\", \"忘记\", \"带来\", \"关心\"\n",
    "]\n",
    "\n",
    "\n",
    "TARGET_SENTENCES = 5\n",
    "BATCH_SIZE = 20   # ask for several at once\n",
    "\n",
    "def is_valid(sentence, allowed):\n",
    "    words = sentence.lower().split('')\n",
    "    return all(word in allowed for word in words)\n",
    "\n",
    "def get_prompt(known_words, target_words, n):\n",
    "    prompt = f\"\"\"\n",
    "You may ONLY use words from the \"Known words\" list\n",
    "and the \"Target words\" list.\n",
    "Do NOT use any other words.\n",
    "You may repeat words.\n",
    "Make sure that each sentence has exactly ONE word from the\n",
    "\"Target words\" list, and the rest are from the \"Known words\" list.\n",
    "Do NOT use punctuation, but DO put a space between the words in a sentence.\n",
    "\n",
    "Known words:\n",
    "{\",\".join(known_words)}\n",
    "\n",
    "Target words:\n",
    "{\",\".join(target_words)}\n",
    "\n",
    "Task:\n",
    "Write {n} idiomatic, normal-sounding sentences.\n",
    "Each sentence must contain exactly one word from the \"Target words\" list\n",
    "and have the rest be from the \"Known words\" list.\n",
    "One sentence per line.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "sentences = []\n",
    "\n",
    "#while len(sentences) < TARGET_SENTENCES:\n",
    "if True:\n",
    "    #remaining = TARGET_SENTENCES - len(sentences)\n",
    "    prompt = get_prompt(KNOWN_WORDS, TARGET_WORDS,TARGET_SENTENCES )\n",
    "\n",
    "    response = client.responses.create(\n",
    "        # model=\"gpt-4.1-mini\",\n",
    "        model = \"gpt-4.1-nano\",\n",
    "        input=prompt\n",
    "    )\n",
    "\n",
    "    lines = response.output_text.strip().splitlines()\n",
    "    print(lines)\n",
    "\n",
    "    for line in lines:\n",
    "        words_in_line = line.split()\n",
    "        n_target = len([w for w in words_in_line if w in TARGET_WORDS])\n",
    "        print(n_target, '   ', line)\n",
    "        if n_target == 1:\n",
    "            sentences.append(line)\n",
    "\n",
    "# Done\n",
    "print('\\n')\n",
    "for i, s in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {s}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
